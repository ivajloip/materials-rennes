\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,bulgarian]{babel}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{multicol}
\usepackage{listings}
\usepackage{xcolor}

\oddsidemargin 0mm
\evensidemargin 0mm
\topmargin 0mm
\textheight 216mm
\textwidth 165mm

\pagestyle{fancy}
\fancyhf{}
\fancyhead[CE,CO]{DAC Homework \#1}
\fancyfoot[CE,CO]{\thepage}

\lstset{basicstyle=\ttfamily,
  mathescape=true,
  escapeinside=||,
  emph={Task, Operation, for, each, if, else, endif, endfor, while, then, When, do, repeat, until, endrepeat},
  emphstyle={\color{gray}\bfseries\itshape}}

\def\CC {{\mathbb C}}        % комплексни числа
\def\RR {{\mathbb R}}        % реални числа
\def\ZZ {{\mathbb Z}}        % цели числа
\def\NN {{\mathbb N}}        % естествени числа
\def\be  {\begin{eqnarray}}  % формула с номерация
\def\ee  {\end{eqnarray}}    % край на формулата
\def\ben {\begin{eqnarray*}} % формула без номерация
\def\een {\end{eqnarray*}}   % край на \bena
\newcommand{\hr}{\rule{\linewidth}{0.1mm}}
\newcommand{\bighs}{\hspace{15pt}}
\newcommand{\hs}{\hspace{10pt}}
\renewcommand{\tilde}{\overset{-}}

\newenvironment{itemize*}{
  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}
}{
  \end{itemize}
}

\newenvironment{enumerate*}{
  \begin{enumerate}
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}
}{
  \end{enumerate}
}

%\renewenvironment{proof}[1][\proofname]{}{\qed}

\newtheoremstyle{plain}{1pt}{0pt}{}{}{}{}{.5em}{\thmname{\textbf{#1}}:\thmnote{#3}}

\theoremstyle{plain}

% Прави формулите да са с нормален шрифт на текста (примерно дробите не стават по-малки)
\everymath{\displaystyle}

\begin{document}

\section*{\centering
  Distributed computing: computability and algorithms 2013-2014 \\
  Homework \#1 \\
  Ivaylo Petrov and Hristina Hristova 
}

\hr

\section*{\textbf{Part 1: Reliable channels with ordering properties}
}

Firstly, we will suggest an algorithm that implements a communication channel 
on which messages with type \emph{ordinary, marker, ct\_future} or 
\emph{ct\_past} can be sent and received, and secondly we will show that the
algorithm is genuine and works correctly.

\subsection*{1. The algorithm}

Let a process $p_i$ sends a message to a process $p_j$. Each protocol message
carries four values: \emph{m, type, sn, barrier} where \emph{m} is the original
message, \emph{type} is the type of the message, \emph{sn} is the sequence
number of the message and \emph{barrier} determines the ordering in the
delivery as describes in the tasks text.  The idea of the algorithm is that
process $p_i$ keeps in a local variable \emph{barrier\_sn} the sequence number
of the last message with type either \emph{cp\_future} or \emph{marker}. We use
this information to compute the barrier of the messages that will be sent. When
a message of type \emph{cp\_past} or a message of type \emph{ordinary} has to
be sent, it does not have any influence on the barrier of the messages which
will be sent after it or of the already sent messages. In order to handle
\emph{ct\_future} and \emph{marker} messages, our algorithm uses the
\emph{barrier\_sn} variable to correctly define the barrier so that the each
message has information about other messages sent before it which have to be
delivered first.  

When the process $p_j$ receives the message it has to decide whether to
deliver it directly (in this case the message will be kept in the set of the
delivered messages) or to wait for other messages that should be delivered first
(these messages are also kept in a set). When a message that has to be
immediately delivered is received, all the message in the "waiting" set are
checked to see if some of them can be delivered as well (using the information
from the barrier and the knowledge which messages have already been delivered).

\clearpage

\begin{lstlisting}[frame=single]
Operation: $p_i$.SEND(m, type) to $p_j$:
  sn := sn++
  if type(m) is ct_future:
    barrier := barrier_sn;
    barrier_sn := sn;
  endif
  if type(m) is ct_past:
    barrier := sn - 1;
  endif
  if type(m) is marker:
    barrier := sn - 1;
    barrier_sn := sn;
  endif
  if type(m) is ordinary:
    barrier := barrier_sn;
  endif
  send MSG(m, type, sn, barrier) to $p_j$

When MSG(m, type, sn, barrier) is received from $p_i$ by $p_j$:
  let delivered_msgs be the set of the delivered 
    msgs to $p_j$, sent by $p_i$ before receiving m;
  let waiting_msgs be the set of the msgs $m'$ sent by
    $p_i$ to $p_j$ that still can not be delivered
    due to their barrier restriction (what we mean
    here is that either their barrier is not delivered
    yet, or if they are of type ct_past or marker,
    there was a message with sequence number $\in \{0, \dots, sn - 1\}$
    that is not delivered and as a consequence, 
    $m'$ can not still be delivered, because it will 
    bypass that message);
    
    are_all_past_messages_delivered = $\nexists m'$ with sequence number $\in$ 
        {0, $\dots$, sn - 1} that is not delivered
    if [m.barrier is in delivered_msgs and
          type(m) $\notin$ {ct_past, ct_marker}] or
       [type(m) $\in$ {ct_past, ct_marker} and
          are_all_past_messages_delivered]
      deliver(m);
      add m to delivered_msgs

    let to_be_delivered_msgs be that subset of the
      set waiting_msgs that waited only for m in order
      to be delivered 
    for each msg in to_be_delivered_msgs:
      deliver(msg);
      add msg to delivered_msgs
      to_be_delivered_msgs := to_be_delivered_msgs $\cup$
        $\{m' | m' \in waiting\_msgs \text{ and msg is preventing m' from being delivered}\}$
  else:
    add m to waiting_msgs
  endif

  return(ok)
 
\end{lstlisting}


In order to be able to use the barrier, we need some information about the 
sequence numbers of the messages - which have already been delivered and which
are still to be delivered. Note that any sequence number (i.e. value that is a
correct sequence number) is expected to be delivered at some point. To be able
to do that, we can do a variety of things. The first thing that comes to mind 
is to put every sequence number that is delivered in a set. This however is not
an efficient solution, as over time this set will continually grow in size.
A better approach would be to have a number that marks the sequence number n
for which messages 1, $\dots$, n are delivered, and this is not true for n + 1.
We would also need a set of messages that have sequence number grater than 
n + 1. When we want to add a message to this structure, we check if its number
is n + 1. If that is the case, we increment the value of n and we also check
for the numbers in the set if they are n + 1 (the new n). We do this until
this set is empty or the number n + 1 is not in the set. 
If the number that we receive is not n + 1, then we just add it to the set.
When we have to check if a given number m is already in our data structure,
we check if m $\le$ n. In this case we know that m has been delivered. Otherwise
we check if m belongs to the set. If it is not in the set, we haven't delivered
it yet.
The idea of the proposed algorithm is to handle the problem with the growing
size of the set of the delivered messages. We make the assumption that the
messages are delivered approximately within some time boundaries, i.e. it is
impossible that almost all the messages with sequence numbers up to 100000
have been delivered, except for 1.

The messages that wait to be delivered can be stored either in a set (this
might lead to slower use later), or an association array that for each possible
barrier associates a set (possibly empty) of all the messages that are waiting
for it. This way it is quite easy when a new message that can be delivered,
arrives, to deliver it and then check if it blocks other messages and 
deliver them as well.

\newtheorem*{th1}{2.  Theorem}
\begin{th1}
  The algorithm is genuine and it works correctly.
\end{th1}
\begin{proof}[Proof:]
  To prove the theorem we will show that the algorithm holds for both the
  liveness property and safety property.
  \begin{enumerate}
    \item We will prove the liveness property first. Since we have a reliable
      channel, messages are not lost and the processes do not fail. So a sent 
      message from a process $p_i$ will be eventually received  from a process 
      $p_j$. In our algorithm $p_i$ sends a message \emph{m} only once. It
      cannot be lost and furthermore, it will be received by $p_j$ exactly once
      because the channel cannot duplicate the sent messages. \\
    \item Now we will show that the safety property is correct too. Let us
      assume a message \emph{m} with type \emph{ct\_future} that has been
      received from $p_j$. For every next message, whatever its type, it will
      always have a barrier \emph{m} (because we set the \emph{barrier\_sn} to
      \emph{m}) or its barrier will be some message sent after \emph{m}. By this
      we conclude that each message sent after \emph{m} will be delivered after
      \emph{m}. \\
      Now if \emph{m} is of type \emph{ct\_past} we know that it will be
      delivered after the previous message sent (the barrier of \emph{m} will
      that message). The algorithm also forces a message of type \emph{ct\_past}
      to wait before being delivered if there are messages with a sequence
      number less than the sequence number of \emph{m} which are not even
      received from $p_j$ yet. So when every single of these messages is
      received and deliver, the process $p_j$ delivers \emph{m} as well. So it
      is impossible \emph{m} to be delivered before any of the messages sent
      before it. \\
      If the type of \emph{m} is \emph{marker}, \emph{m} will behave like a
      message of type \emph{ct\_past} for the messages sent before it. But we
      also make \emph{barrier\_sn} to be equal to \emph{m} and this way every
      next message will have a barrier which is bigger or equal to the sequence
      number of \emph{m}. \\
      Finally, if the type of \emph{m} is \emph{ordinary} its barrier will be
      the last message of type either \emph{ct\_future} or \emph{marker} sent
      before \emph{m}. This means that \emph{m} cannot bypass either one of
      these two types of messages.
  \end{enumerate}
\end{proof}

\section*{\textbf{Part 2: Implementing a heartbeat failure detector}}

\subsection*{1. The algorithm} % (fold)
\label{sub:The algorithm}

The main idea of the algorithm is that either periodically (at some velocity
that is specific to each process, and has nothing to do with the velocities
of any of the other processes) or when some event appears (a message is sent or
received, including acknowledgment for message received) some specific behavior 
is executed. The thing that is executed is the action that is needed in order
for our implementation of the heart-beat algorithm to work. 

Here is what is the thing that is executed (you may want to notice that if a 
process is not faulty, then it will execute this infinitely):
\begin{itemize}
  \item Each process sends I\_AM\_ALIVE message to all its neighbors.
  \item Each process sends information about the state of all the processes 
    from its perspective. Namely, it sends an array \emph{statuses} that contains
    some counter value for each of the other processes. For every process in
    this array we have how much times this process has sent I\_AM\_ALIVE and
    this has been received by some other process (this is not completely
    precise, but a more accurate explanation will be given shortly). To ensure
    that this update will be received, each process sends it to all of its 
    neighbors until it receives an acknowledgment (ACK) and then it starts to
    send them newer information (the most recent information it knows). By
    sending the same information (the same message), we are sure that if the
    channel between the two processes is fair, the message will be received
    at some point (and the ACK will be received, too).

    So basically each process sends to its neighbors some state of the status
    of all the other processes. It might not be the most recent that the process
    has, but it is newer than the last one that they have confirmed to have
    received from that processor. The confirmation is individual and so it is
    possible to send to different neighbors different states (if some of them 
    have not confirmed an old state, we will still send them an old state,
    until they confirm it). By doing this, we are sure that from time to time
    every process will receive a newer status of all the other processes and
    thus will know that they are not faulty. 

    If there is a faulty process (let it be $p_i$), it will stop sending
    I\_AM\_ALIVE message at some finite point and by that time it will have
    generated a finite number of messages. When all those messages are either
    received or lost, the counter for $p_i$ will stop increasing and after 
    some finite amount of time every correct process will have the last value
    for the counter of $p_i$ and will never receive a greater value for this
    counter. That way the requirement of the heart-beat algorithm will not be
    violated.

    Now let us describe what happens when \textbf{an update is received}. If the
    value for some of the processes in the update is greater than the one that
    we have for that process, we update our counter. Otherwise we do nothing.

    When an \textbf{I\_AM\_ALIVE} is received from $p_i$, we just increase the
    counter for that process. Note that if the process $p_i$ is correct, 
    it will send an infinite number of times this message. If we are connected
    by a fair channel with it, we will receive an infinite number of
    \textbf{I\_AM\_ALIVE} messages from it for an infinite amount of time.
    And as a consequence we will increase its counter infinitely. Also note that
    at least one correct process should be connected to $p_i$ with a fair
    channel (this comes from the requirements of the task), so it will increase
    infinitely its counter for $p_i$ and will send this information to all other
    correct processes (maybe indirectly) with its updates.

    It is possible that not all the messages received from some process (let it
    be $p_i$) will be counted. Here is how this can occur: if all the processes
    are connected to $p_i$ and it broadcast an \textbf{I\_AM\_ALIVE} message
    and this message is received by every other process and they have the same
    value for the counter of $p_i$, then all those $n$ messages will be counted
    only once. This however is not a problem, because this is the same as if
    our channel has lost $n - 1$ messages, which will not affect the described
    algorithm.
\end{itemize}

\clearpage

\begin{lstlisting}[frame=single]
Operation: $p_i$ SEND_STATUSES() to $neighbours_i$:
  for each neighbour in $neighbours_i$:
    let statuses be a dictionary of the status msgs $p_i$ will
    send to each its neighbour (the initial value for each
    element in statuses will be 0)
    for each neighbour in statuses:
      repeat (send MSG(neighbour) to $neighbours_i$);
      until recieve(ACK(neighbour)) from neighbour;

  let $HB_i$ be the most recent status we have in process $p_i$;

  when $p_i$ receives(ACK(statuses)) from some neighbour in
    $neighbours_i$:
    statuses[neighbour] = $HB_i$

When $p_j$ RECEIVE_STATUSES(statuses) from $p_i$:
  send ACK(statuses) to $p_i$;

  for each process in statuses:
    if $HB_j$[process] $\le$ statuses[process]:
      $HB_j$[process] := statuses[process];

  $HB_j$[i] := $HB_j$[i] + 1;
  
\end{lstlisting}
% subsection The algorithm (end)
  
The explanation of the algorithm makes it clear that the completeness property
of the heartbeat failure detector is correct. If a process is faulty, after some
fixed time its heartbeat will no longer be increased because he will no longer
send statuses (including its own). The algorithm holds for the liveness property
as well. No process decreases the value of the heartbeat and moreover, if a
process is correct, its heartbeat can increase infinitely.\\

\newtheorem*{th2}{2. Theorem}
\begin{th2}
  The algorithm is genuine for a fair channel and for a fair lossy channel.
\end{th2}
\begin{proof}[Proof]
  As we have seen earlier the algorithm is working correctly for a fair channel.
  We will seen that this is the case with a fair lossy channel. \\
  We know that for each pair of correct processes there is a fair path that
  connects them. This means that since a status message is sent infinite
  number of times, at least once it will be received from a correct process and
  the statuses will be updated. This way a process can indicate which ones of
  its neighbours are correct. The liveness and the completeness properties are
  also taken into account in a fair lossy channel. The heartbeat of a correct
  process can increase infinitely because its status/statuses will not be lost.
  For a faulty process the heartbeat will stop increasing after some point in
  time.
\end{proof}
\end{document}
