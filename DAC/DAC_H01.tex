\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,bulgarian]{babel}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{multicol}
\usepackage{listings}
\usepackage{xcolor}

\oddsidemargin 0mm
\evensidemargin 0mm
\topmargin 0mm
\textheight 216mm
\textwidth 165mm

\pagestyle{fancy}
\fancyhf{}
\fancyhead[CE,CO]{DAC Homework \#1}
\fancyfoot[CE,CO]{\thepage}

\lstset{basicstyle=\ttfamily,
  mathescape=true,
  escapeinside=||,
  emph={Task, Operation, for, each, if, else, endif, endfor, while, then, When, do, repeat, until, endrepeat},
  emphstyle={\color{gray}\bfseries\itshape}}

\def\CC {{\mathbb C}}        % комплексни числа
\def\RR {{\mathbb R}}        % реални числа
\def\ZZ {{\mathbb Z}}        % цели числа
\def\NN {{\mathbb N}}        % естествени числа
\def\be  {\begin{eqnarray}}  % формула с номерация
\def\ee  {\end{eqnarray}}    % край на формулата
\def\ben {\begin{eqnarray*}} % формула без номерация
\def\een {\end{eqnarray*}}   % край на \bena
\newcommand{\hr}{\rule{\linewidth}{0.1mm}}
\newcommand{\bighs}{\hspace{15pt}}
\newcommand{\hs}{\hspace{10pt}}
\renewcommand{\tilde}{\overset{-}}

\newenvironment{itemize*}{
  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}
}{
  \end{itemize}
}

\newenvironment{enumerate*}{
  \begin{enumerate}
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}
}{
  \end{enumerate}
}

%\renewenvironment{proof}[1][\proofname]{}{\qed}

\newtheoremstyle{plain}{1pt}{0pt}{}{}{}{}{.5em}{\thmname{\textbf{#1}}:\thmnote{#3}}

\theoremstyle{plain}

% Прави формулите да са с нормален шрифт на текста (примерно дробите не стават по-малки)
\everymath{\displaystyle}

\begin{document}

\section*{\centering
  Distributed computing: computability and algorithms 2013-2014 \\
  Homework \#1 \\
  Ivaylo Petrov and Hristina Hristova 
}

\hr

\section*{\textbf{Part 1: Reliable channels with ordering properties}
}

  Firstly, we will suggest an algorithm that implements a communication channel 
  on which messages with type \emph{ordinary, marker, ct\_future} or 
  \emph{ct\_past} can be sent and received, and secondly we will show that the
  algorithm is genuine.

\subsection*{1. The algorithm}

Let a process $p_i$ sends a message to a process $p_j$. Each protocol message
carries four values: \emph{m, type, sn, barrier}. The idea of the algorithm
is that process $p_i$ keeps in a local variable \emph{barrier\_sn} the
sequence number of the last message with type either \emph{cp\_future} or
\emph{marker}. We use this information to define the barrier of the messages
that will be sent. When a message of type \emph{cp\_past} or a message of
type \emph{ordinary} has to be sent, it does not have any influence on the
barrier of the messages which will be sent after it or of the already sent
messages. In order to handle \emph{ct\_future} and \emph{marker} messages,
our algorithm uses the \emph{barrier\_sn} variable to correctly define the
barrier so that the each message has information about other messages
sent before it which have to be delivered first.

When the process $p_j$ receives the message it has to decide whether to
deliver it directly (in this case the message will be kept in the set of the
delivered messages) or to wait for its barrier to be received and delivered
first (these messages are also kept in a set). When a message that has to be
immediately delivered is received, all the message in the "waiting" set
whose barrier is the received message will be delivered as well.

\clearpage

\begin{lstlisting}[frame=single]
Operation: $p_i$.SEND(m, type) to $p_j$:
  sn := sn++
  if type(m) is ct_future:
    barrier := barrier_sn;
    barrier_sn := sn;
  endif
  if type(m) is ct_past:
    barrier := sn - 1;
  endif
  if type(m) is marker:
    barrier := sn - 1;
    barrier_sn := sn;
  endif
  if type(m) is ordinary:
    barrier := barrier_sn;
  endif
  send MSG(m, type, sn, barrier) to $p_j$

When MSG(m, type, sn, barrier) is received from $p_i$ by $p_j$:
  let delivered_msgs be the set of the delivered 
    msgs sent by $p_i$ before reveiving m;
  let waiting_msgs be the set of the msgs sent by
    $p_i$ whose barrier has not been delivered before
    receiving m;
    
    are_all_past_messages_delivered = $\nexists m'$ with sequence number $\in$ 
        {0, $\dots$, sn - 1} that is not delivered
    if [m.barrier is in delivered_msgs and
          type(m) $\notin$ {ct_past, ct_marker}] or
       [type(m) $\in$ {ct_past, ct_marker} and
          are_all_past_messages_delivered]
      deliver(m);
      add m to delivered_msgs

    let to_be_delivered_msgs be that subset of the
      set waiting_msgs that waited only for m in order
      to be delivered (what we mean here is that either m
      was their barrier, or if they are of type ct_past or
      marker, m was the only message that currently prevents
      such messages from delivering because they had to wait
      for m in order not to bypass it.)

    for each msg in to_be_delivered_msgs:
      deliver(msg);
      add msg to delivered_msgs
      to_be_delivered_msgs := to_be_delivered_msgs $\cup$
        $\{m' | m' \in waiting\_msgs \text{ and msg is preventing m' from being delivered}\}$
  else:
    add m to waiting_msgs
  endif

  return(ok)
 
\end{lstlisting}

\clearpage

In order to be able to use the barrier, we need some information about the 
sequence numbers of the messages - which have already been delivered and which
are still to be delivered. Note that any sequence number (i.e. value that is a
correct sequence number) is expected to be delivered at some point. To be able
to do that, we can do a variety of things. The first thing that comes to mind 
is to put every sequence number that is delivered in a set. This however is not
an efficient solution, as over time this set will continually grow in size.
A better approach would be to have a number that marks the sequence number n
for which messages 1, $\dots$, n are delivered, and this is not true for n + 1.
We would also need a set of messages that have sequence number grater than 
n + 1. When we want to add a message to this structure, we check if its number
is n + 1. If that is the case, we increment the value of n and we also check
for the numbers in the set if they are n + 1 (the new n). We do this until
this set is empty or the number n + 1 is not in the set. 
If the number that we receive is not n + 1, then we just add it to the set.
When we have to check if a given number m is already in our data structure,
we check if m $\le$ n. In this case we know that m has been delivered. Otherwise
we check if m belongs to the set. If it is not in the set, we haven't delivered
it yet.
The idea of the proposed algorithm is to handle the problem with the growing
size of the set of the delivered messages. We make the assumption that the
messages are delivered approximately within some time boundaries, i.e. it is
impossible that almost all the messages with sequence numbers up to 100000
have been delivered, except for 1.

The messages that wait to be delivered can be stored either in a set (this
might lead to slower use later), or an association array that for each possible
barrier associates a set (possibly empty) of all the messages that are waiting
for it. This way it is quite easy when a new message that can be delivered,
arrives, to deliver it and then check if it blocks other messages and 
deliver them as well.

\newtheorem*{th1}{2.  Theorem}
\begin{th1}
  The algorithm is genuine and it works correctly.
\end{th1}
\begin{proof}[Proof:]
  To prove the theorem we will show that the algorithm holds for both the
  liveness property and safety property.
  \begin{enumerate}
    \item We will prove the liveness property first. Since we have a reliable
      channel, messages are not lost and the processes do not fail. So a sent 
      message from a process $p_i$ will be eventually received  from a process 
      $p_j$. In our algorithm $p_i$ sends a message \emph{m} only once. It
      cannot be lost and furthermore, it will be received by $p_j$ exactly once
      because the channel cannot duplicate the sent messages. \\
    \item Now we will show that the safety property is correct too. Let us
      assume a message \emph{m} with type \emph{ct\_future} that has been
      received from $p_j$. For every next message, whatever its type, it will
      always have a barrier \emph{m} (because we set the \emph{barrier\_sn} to
      \emph{m}) or its barrier will be some message sent after \emph{m}. By this
      we conclude that each message sent after \emph{m} will be delivered after
      \emph{m}. \\
      Now if \emph{m} is of type \emph{ct\_past} we know that it will be
      delivered after the previous message sent (the barrier of \emph{m} will
      that message). The algorithm also forces a message of type \emph{ct\_past}
      to wait before being delivered if there are messages with a sequence
      number less than the sequence number of \emph{m} which are not even
      received from $p_j$ yet. So when every single of these messages is
      received and deliver, the process $p_j$ delivers \emph{m} as well. So it
      is impossible \emph{m} to be delivered before any of the messages sent
      before it. \\
      If the type of \emph{m} is \emph{marker}, \emph{m} will behave like a
      message of type \emph{ct\_past} for the messages sent before it. But we
      also make \emph{barrier\_sn} to be equal to \emph{m} and this way every
      next message will have a barrier which is bigger or equal to the sequence
      number of \emph{m}. \\
      Finally, if the type of \emph{m} is \emph{ordinary} its barrier will be
      the last message of type either \emph{ct\_future} or \emph{marker} sent
      before \emph{m}. This means that \emph{m} cannot bypass either one of
      these two types of messages.
  \end{enumerate}
\end{proof}

\section*{\textbf{Part 2: <CHANGE ME>}}

\subsection{The algorithm} % (fold)
\label{sub:The algorithm}

The main idea of the algorithm is that either periodically (at some velocity
that is specific to each process, and has nothing to do with the velocities
of any of the other processes) or when some event appears (a message is sent or
received, including acknowledgment for message received) some specific behavior 
is executed. The thing that is executed is the action that is needed in order
for our implementation of the heart-beat algorithm to work. 

Here is what is the thing that is executed (you may want to notice that if a 
process is not faulty, then it will execute this infinitely):
\begin{itemize}
  \item Each process sends I\_AM\_ALIVE message to all its neighbors.
  \item Each process sends information about the state of all the processes 
    from its perspective. Namely, it sends an array \emph{statuses} that contains
    some counter value for each of the other processes. For every process in
    this array we have how much times this process has sent I\_AM\_ALIVE and
    this has been received by some other process (this is not completely
    precise, but a more accurate explanation will be given shortly). To ensure
    that this update will be received, each process sends it to all of its 
    neighbors until it receives an acknowledgment (ACK) and then it starts to
    send them newer information (the most recent information it knows). By
    sending the same information (the same message), we are sure that if the
    channel between the two processes is fair, the message will be received
    at some point (and the ACK will be received, too).

    So basically each process sends to its neighbors some state of the status
    of all the other processes. It might not be the most recent that the process
    has, but it is newer than the last one that they have confirmed to have
    received from that processor. The confirmation is individual and so it is
    possible to send to different neighbors different states (if some of them 
    have not confirmed an old status, we will still send them an old status,
    until they confirm it). By doing this, we are sure that from time to time
    every process will receive a newer status of all the other processes and
    thus will know that they are not faulty. 

    If there is a faulty process (let it be $p_i$), it will stop sending
    I\_AM\_ALIVE message at some finite point and by that time it will have
    generated a finite number of messages. When all those messages are either
    received or lost, the counter for $p_i$ will stop increasing and after 
    some finite amount of time every correct process will have the last value
    for the counter of $p_i$ and will never receive a greater value for this
    counter. That way the requirement of the heart-beat algorithm will not be
    violated.

    Now let us describe what happens when \textbf{an update is received}. If the
    value for some of the processes in the update is greater than the one that
    we have for that process, we update our counter. Otherwise we do nothing.

    When an \textbf{I\_AM\_ALIVE} is received from $p_i$, we just increase the
    counter for that process. Note that if the process $p_i$ is correct, 
    it will send an infinite number of times this message. If we are connected
    by a fair channel with it, we will receive an infinite number of
    \textbf{I\_AM\_ALIVE} messages from it for an infinite amount of time.
    And as a consequence we will increase its counter infinitely. Also note that
    at least one correct process should be connected to $p_i$ with a fair
    channel (this comes from the requirements of the task), so it will increase
    infinitely its counter for $p_i$ and will send this information to all other
    correct processes (maybe indirectly) with its updates.
    
\end{itemize}

\begin{lstlisting}[frame=single]
Operation: $p_i$ SEND_STATUSES() to $neighbours_i$:
  for each neighbour in $neighbours_i$:
    let statuses be a dictionary of the status msgs $p_i$ will send to each its
    neighbour (the initial value for each element in statuses will be 0)
    for each neighbour in statuses:
      repeat (send MSG(neighbour) to $neighbours_i$);
      until recieve(ACK(neighbour)) from neighbour;

  let latest_statuses be the most recent statuses
  we have received;

  when $p_i$ receives(ACK(statuses)) from some neighbour in $neighbours_i$:
    statuses[neighbour] = latest_statuses

When $p_j$ RECEIVE_STATUSES(statuses) from $p_i$:
  send ACK(statuses) to $p_i$;

  for each process in statuses:
    if $HB_j$[process] $\le$ $HB_i$[process]:
      $HB_j$[process] := $HB_i$[process];

  $HB_j$[i] := $HB_j$[i] + 1;
  
\end{lstlisting}
% subsection The algorithm (end)
  
  
\end{document}
